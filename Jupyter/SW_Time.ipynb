{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV data took 53.43 ms\n",
      "Current normalization took 0.39 ms\n",
      "Park's transformation took 2.03 ms\n",
      "Complex vector calculation took 1.66 ms\n",
      "find_first_zero_crossing took 0.75 ms\n",
      "find_first_zero_crossing took 1.31 ms\n",
      "find_first_zero_crossing took 1.52 ms\n",
      "find_zero_crossings took 5.36 ms\n",
      "Signal processing took 0.34 ms\n",
      "Writing statistics to CSV file took 7.49 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "\n",
    "def profile_execution(func):\n",
    "    \"\"\"Decorator to measure execution time of functions\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()\n",
    "        print(f\"{func.__name__} took {(end_time - start_time)*1000:.2f} ms\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@profile_execution\n",
    "def find_first_zero_crossing(Bcurr, startIdx):\n",
    "    \"\"\"Find the first zero crossing from a given index\"\"\"\n",
    "    for i in range(int(startIdx), len(Bcurr) - 1):\n",
    "        if Bcurr[i] * Bcurr[i + 1] <= 0:\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "@profile_execution\n",
    "def find_zero_crossings(Bcurr, Tms):\n",
    "    \"\"\"Find three consecutive zero crossings\"\"\"\n",
    "    Bzero_cross_i = find_first_zero_crossing(Bcurr, 1)\n",
    "    Bsecond_zero_cross_i = find_first_zero_crossing(Bcurr, Bzero_cross_i + (1000/Tms))\n",
    "    Bthird_zero_cross_i = find_first_zero_crossing(Bcurr, Bsecond_zero_cross_i + (1000/Tms))\n",
    "    return Bzero_cross_i, Bsecond_zero_cross_i, Bthird_zero_cross_i\n",
    "\n",
    "def calc_statistics(data):\n",
    "    # Number of data points\n",
    "    n = len(data)\n",
    "\n",
    "    # Calculate mean\n",
    "    mean_val = np.mean(data)\n",
    "\n",
    "    # Calculate standard deviation\n",
    "    std_dev = np.std(data)\n",
    "\n",
    "    # Find min and max for peak to peak\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "\n",
    "    # Calculate RMS\n",
    "    rms_val = np.sqrt(np.mean(np.square(data)))\n",
    "\n",
    "    # Calculate absolute mean for shape and impulse factors\n",
    "    mean_abs = np.mean(np.abs(data))\n",
    "\n",
    "    # Calculate skewness and kurtosis\n",
    "    skewness_val = (np.mean((data - mean_val) ** 3)) / (std_dev ** 3)\n",
    "    kurtosis_val = (np.mean((data - mean_val) ** 4)) / (std_dev ** 4) - 3.0\n",
    "\n",
    "    # Output results\n",
    "    results = {\n",
    "        'mean': mean_val,\n",
    "        'std_dev': std_dev,\n",
    "        'skewness': skewness_val,\n",
    "        'kurtosis': kurtosis_val,\n",
    "        'peak_to_peak': max_val - min_val,  # peak to peak\n",
    "        'rms': rms_val,\n",
    "        'crest_factor': max_val / rms_val,  # crest factor\n",
    "        'shape_factor': rms_val / mean_abs, # shape factor\n",
    "        'impulse_factor': max_val / mean_abs,  # impulse factor\n",
    "        'margin_factor': max_val / (mean_abs ** 2), # margin factor\n",
    "        'energy': np.sum(np.square(data))  # energy\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    # Define constants for base currents and sampling time\n",
    "    IbaseR = 4.79\n",
    "    IbaseY = 4.54\n",
    "    IbaseB = 4.56\n",
    "    Tms = 50\n",
    "    filename = 'H_L2_1.csv'\n",
    "\n",
    "    # Measure data loading time\n",
    "    start_time = time.perf_counter()\n",
    "    data = []\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next(csvfile)  # Skip the first two header rows\n",
    "        next(csvfile)\n",
    "        for row in csvreader:\n",
    "            data.append([float(value) for value in row])\n",
    "\n",
    "    print(f\"Loading CSV data took {(time.perf_counter() - start_time)*1000:.2f} ms\")\n",
    "\n",
    "    # Convert to numpy array for easier manipulation\n",
    "    data = np.array(data)\n",
    "\n",
    "    # Create time vector\n",
    "    time_vec = np.linspace(0, Tms/1000, 1002)\n",
    "\n",
    "    # Extract and normalize currents\n",
    "    start_time = time.perf_counter()\n",
    "    Rx, Yx, Bx = data[:, 2], data[:, 4], data[:, 6]\n",
    "    R1, Y1, B1 = Rx / IbaseR, Yx / IbaseY, Bx / IbaseB\n",
    "    print(f\"Current normalization took {(time.perf_counter() - start_time)*1000:.2f} ms\")\n",
    "\n",
    "    # Apply Park's Transformation\n",
    "    start_time = time.perf_counter()\n",
    "    curr_vect = np.vstack((R1, Y1, B1))\n",
    "    Tcmat = np.sqrt(2/3) * np.array([\n",
    "        [1, -1/2, -1/2],\n",
    "        [0, np.sqrt(3)/2, -np.sqrt(3)/2],\n",
    "        [1/np.sqrt(2), 1/np.sqrt(2), 1/np.sqrt(2)]\n",
    "    ])\n",
    "    op = np.dot(Tcmat, curr_vect)\n",
    "    Id, Iq, Io = op[0, :], op[1, :], op[2, :]\n",
    "    print(f\"Park's transformation took {(time.perf_counter() - start_time)*1000:.2f} ms\")\n",
    "\n",
    "    # Calculate complex vector magnitude\n",
    "    start_time = time.perf_counter()\n",
    "    Pv = Id + 1j * Iq\n",
    "    Pvm = np.abs(Pv)\n",
    "    print(f\"Complex vector calculation took {(time.perf_counter() - start_time)*1000:.2f} ms\")\n",
    "\n",
    "    # Find zero crossings\n",
    "    Bzero_cross_i, Bsecond_zero_cross_i, Bthird_zero_cross_i = find_zero_crossings(Iq, Tms)\n",
    "\n",
    "    # Extract and process one cycle\n",
    "    start_time = time.perf_counter()\n",
    "    Pv2 = Pvm[Bzero_cross_i:Bthird_zero_cross_i]\n",
    "    Pv3 = Pv2 - np.mean(Pv2)\n",
    "    print(f\"Signal processing took {(time.perf_counter() - start_time)*1000:.2f} ms\")\n",
    "\n",
    "    # Calculate statistics for the processed signal\n",
    "    statistics = calc_statistics(Pv3)\n",
    "\n",
    "    # Write statistics to a CSV file\n",
    "    output_filename = 'statistics_output.csv'\n",
    "    with open(output_filename, mode='w', newline='') as csvfile:\n",
    "        fieldnames = ['statistic', 'value']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for key, value in statistics.items():\n",
    "            writer.writerow({'statistic': key, 'value': value})\n",
    "\n",
    "    print(f\"Writing statistics to CSV file took {(time.perf_counter() - start_time)*1000:.2f} ms\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
